\documentclass{article}

\usepackage{noweb}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[colorlinks,linkcolor=blue]{hyperref}
\usepackage{parskip}
\usepackage{microtype}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage[titletoc,title]{appendix}

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\newcommand{\exprref}[1]{Expression~\ref{#1}}

\title{Exploiting CNF Common Clauses for Faster Evaluation}
\author{Vincent Foley}

\begin{document}

\maketitle

\begin{abstract}
\noindent
We show how representing boolean expressions in conjunctive-normal form (CNF)
allows for an evaluation strategy that
(1) avoids unnecessarily recomputing common clauses, and
(2) can avoid evaluating an expression if one of its clauses has already failed.
\end{abstract}

\section{Introduction}

The core task of \emph{rtb-boolean} is to return a list of flight ids that
match the parameters of a bid request%
\footnote{Other objects such as products and usegments use the same
infrastructure, but to make the language more concrete in this document,
we'll concentrate on flights.}%
.

The current evaluation strategy is simple:
for every flight, we evaluate its associated boolean expression using
the fields and values from the incoming bid request.
If the evaluation succeeds, we record the flight's id in a list of matches.
This strategy is captured in [[<<find matches naively>>]].
In addition to its simplicity, an advantage of this technique
is that it does not require that the
boolean expressions have any specific structure; any combination
of the operators ``AND'', ``OR'', and ``NOT'' is acceptable.

<<find matches naively>>=
fn find_matches(bid_request, flights):
    matches := []
    for i := 0 .. len(flights):
        if eval(bid_request, flights[i].expr):
            matches.add(i)
    return matches
@

The main weakness of this approach is that it considers expressions in
isolation; it does not try to exploit the shared environment (the bid
request) nor the fact that many flights may share common sub-expressions.

To address this weakness, we reformulate the boolean expressions into
CNF and exploit that structure to perform fewer evaluations.

\subsection{Conjunctive-normal form}

An expression is in conjunctive-normal form if it is
a conjunction of clauses.  A clause is a disjunction
of literals, and a literal is either a variable or
the negation of a literal.

In the examples below, \exprref{eq:cnf} is in CNF
because it has three clauses joined by conjuctions, and
none of the clauses uses the conjunctive operator.
\exprref{eq:not-cnf-1} uses conjunction in one of
its sub-expressions, and the clauses of \exprref{eq:not-cnf-2}
are not all joined by conjunctions, and thus neither is in CNF.
We may think that \exprref{eq:not-cnf-3} is in CNF,
however the negation of a clause is not a clause,
and therefore it is not in CNF.

\begin{align}
  \text{\cmark} \quad & X \wedge (Y \vee Z) \wedge \neg W   \label{eq:cnf} \\
  \text{\xmark} \quad & X \wedge (Y \wedge Z) \wedge \neg W \label{eq:not-cnf-1} \\
  \text{\xmark} \quad & X \wedge (Y \wedge Z) \vee \neg W   \label{eq:not-cnf-2} \\
  \text{\xmark} \quad & X \wedge (Y \vee Z) \wedge \neg (W \vee X \vee Y)   \label{eq:not-cnf-3}
\end{align}

\subsection{CNF-aware matching}

If the boolean expressions are in conjunctive-normal form,
we can improve our matching strategy.
The failure of a single clause causes the entire expression
to fail as well;
if a clause $X$ fails (i.e., evaluates to false) in an expression,
we can discard all the subsequent expressions that have $X$ as one of their clause,
because we know they will all fail too.

In the example below, the expressions share the clause $X$.
If during the evaluation of \exprref{eq:expr1} we find that $X = \text{\it false}$,
then we don't need to evaluate any clause of \exprref{eq:expr2}.
This means that the sub-expressions $F$, $G$, and $H$ will never
need to be evaluated.  We hope that skipping clauses in this
way will yield an appreciable speed-up over the na√Øve approach.

\begin{align}
    X \wedge (A \vee B) \wedge C        \label{eq:expr1} \\
    (F \vee G) \wedge X \wedge \neg H   \label{eq:expr2}
\end{align}

\subsection{Implementation}

We will implement a prototype of CNF-aware matching using Rust.
We use Rust for two main reasons: (1) being compiled to machine
code with LLVM, it should give us a fairer assessment of the
performance we can expect when we do the implementation in C;
(2) Rust provides a number of language features that should
help make this prototype easier to write (e.g., enums and
pattern matching) and harder to get wrong (e.g., static
type checking and borrow checking).

\section{Data structures}

In this section, we define the data structure to represent
boolean expressions.

\subsection{Expressions}
\label{sec:expressions}

We first define expressions that are \textbf{not} expected to be in
conjunctive-normal form: they represent the expressions as written by
users.  A later section will automate the conversion to CNF.

To simplify the prototype, we intentionally gut the boolean language
to only 4 constructs, which are described in the enum [[Expr]].
In the complete implementation, we will also have boolean literals,
numeric comparisons, list operations (\emph{all of}, \emph{not in}, etc.),
and functions.  All these will be literals, which is why we allow
ourselves only to have one node (\emph{Var}) as a representative
of literals.

<<type definitions>>=
#[derive(Debug, PartialOrd, PartialEq, Clone)]
enum Expr {
    Var(usize),     // Variables are distinguished by a numeric id
    And(Vec<Expr>), // The conjunction of multiple expressions
    Or(Vec<Expr>),  // The disjunction of multiple expression
    Not(Box<Expr>)  // The negation of an expression
}

impl Expr {
    <<expression methods>>
}
@

\subsection{CNF Expressions}

Let us also define data structures for CNF expressions.
The [[Expr]] enum defined above could be used to represent
a CNF expression, but it does not enforce that an expression
be in conjunctive-normal form.
By defining a type for CNF expressions, CNF clauses, and
literals, we can make sure that it is impossible to even
construct an expression that is not in CNF.

<<type definitions>>=
#[derive(Debug, PartialEq, Clone)]
struct CNFExpr(Vec<CNFClause>);

#[derive(Debug, PartialEq, Clone)]
struct CNFClause(Vec<CNFLiteral>);

#[derive(Debug, PartialEq, Clone)]
enum CNFLiteral {
    Var(usize),
    Not(usize)
}

<<cnf methods>>
@

\paragraph{Simple constructors}
Creating a CNF Expression structure by hand isn't hard,
but it's certainly verbose.  In the next chunk, we introduce
two constructors that are going to simplify some down the line:
[[var]] to create a CNF expression of a single variable, and
[[not]] to create the negation of a single variable.

<<cnf methods>>=
impl CNFExpr {
    fn var(n: usize) -> CNFExpr {
        CNFExpr(vec![CNFClause(vec![CNFLiteral::Var(n)])])
    }

    fn not(n: usize) -> CNFExpr {
        CNFExpr(vec![CNFClause(vec![CNFLiteral::Not(n)])])
    }
}
@

\subsection{Utility methods}

In this subsection we'll implement a number of utility methods
on expressions and CNF expressions.

\paragraph{Display}
Our first order of business is to provide a way to print expressions;
the default format of [[Debug]] quickly gets unreadble
with all the extra boxes and vectors.  We implement the [[Display]]
trait for expressions and for CNF expressions.  We also
deactivate the warnings that are triggered by not using the
result of the [[write!]] macro.

<<functions>>=
impl fmt::Display for Expr {
    #[allow(unused_must_use)]
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match *self {
            Expr::Var(n) => { write!(f, "{}", n) }
            Expr::Not(ref sub) => { write!(f, "!{}", sub) }
            Expr::And(ref subs) => {
                let mut first = true;
                write!(f, "(");
                for sub in subs {
                    if !first { write!(f, " & "); }
                    first = false;
                    write!(f, "{}", sub);
                }
                write!(f, ")")
            }
            Expr::Or(ref subs) => {
                let mut first = true;
                write!(f, "(");
                for sub in subs {
                    if !first { write!(f, " | "); }
                    first = false;
                    write!(f, "{}", sub);
                }
                write!(f, ")")
            }
        }
    }
}
@

<<unit tests>>=
#[test]
fn test_expr_display() {
    use super::Expr;
    assert_eq!("0", format!("{}", Expr::from_str("0")));
    assert_eq!("!0", format!("{}", Expr::from_str("!0")));
    assert_eq!("(0 & 1)", format!("{}", Expr::from_str("0 & 1")));
    assert_eq!("(0 | 1)", format!("{}", Expr::from_str("0 | 1")));
    assert_eq!("(0 | (1 & 2))", format!("{}", Expr::from_str("0 | 1 & 2")));
}
@


<<functions>>=
impl fmt::Display for CNFExpr {
    #[allow(unused_must_use)]
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if self.0.len() == 0 { write!(f, "") }
        else if self.0.len() == 1 { write!(f, "{}", self.0[0]) }
        else {
            let mut first = true;
            for clause in &self.0 {
                if !first { write!(f, " & "); }
                write!(f, "{}", clause);
                first = false;
            }
            write!(f, "")
        }
    }
}

impl fmt::Display for CNFClause {
    #[allow(unused_must_use)]
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if self.0.len() == 0 { write!(f, "") }
        else if self.0.len() == 1 { write!(f, "{}", self.0[0]) }
        else {
            write!(f, "(");
            let mut first = true;
            for clause in &self.0 {
                if !first { write!(f, " | "); }
                write!(f, "{}", clause);
                first = false;
            }
            write!(f, ")")
        }
    }
}

impl fmt::Display for CNFLiteral {
    #[allow(unused_must_use)]
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match *self {
            CNFLiteral::Var(n) => write!(f, "{}", n),
            CNFLiteral::Not(n) => write!(f, "!{}", n)
        }
    }
}
@

<<unit tests>>=
#[test]
fn test_cnf_display() {
    use super::{CNFExpr, CNFClause, CNFLiteral};
    assert_eq!("", format!("{}", CNFExpr(vec!())));
    assert_eq!("0", format!("{}", CNFExpr::var(0)));
    assert_eq!("!0", format!("{}", CNFExpr::not(0)));
    assert_eq!("(0 | 1)", format!("{}",
        CNFExpr(vec!(CNFClause(vec!(CNFLiteral::Var(0),
                                    CNFLiteral::Var(1)))))));
    assert_eq!("(0 | 1) & !2", format!("{}",
        CNFExpr(vec!(CNFClause(vec!(CNFLiteral::Var(0),
                                    CNFLiteral::Var(1))),
                     CNFClause(vec!(CNFLiteral::Not(2)))))));
}
@

\paragraph{Expression size}
Next, we implement a method to return the size of
an expression or a CNF expression.  The size is
the number of variables used in the expression.  This is a useful
metric as some of the conversion to CNF can create
duplicates of some variables. (This is especially
true in the handling of the \emph{or} operator.)

<<expression methods>>=
fn size(&self) -> usize {
    match *self {
        Expr::Var(_) => 1,
        Expr::Not(ref subexpr) => subexpr.size(),
        Expr::Or(ref subexprs)
        | Expr::And(ref subexprs) => subexprs.iter().map(|x| x.size()).sum()
    }
}
@

<<unit tests>>=
#[test]
fn test_size() {
    use super::Expr;
    assert_eq!(0, Expr::Or(vec![]).size());
    assert_eq!(0, Expr::And(vec![]).size());
    assert_eq!(1, Expr::from_str("0").size());
    assert_eq!(1, Expr::from_str("!0").size());
    assert_eq!(2, Expr::from_str("!0 & 1").size());
    assert_eq!(2, Expr::from_str("!0 | !1").size());
}
@


<<cnf methods>>=
impl CNFExpr {
    fn size(&self) -> usize {
        self.0.iter().map(|clause| clause.size()).sum()
    }
}

impl CNFClause {
    fn size(&self) -> usize {
        self.0.len()
    }
}
@



\section{Parsing}

Even simple expressions can become long and hard to understand
if we only use the Rust syntax to read and write them.
To alleviate this task, we create a small parser that can read
expressions as strings and generate the equivalent [[Expr]] structure.

Thanks to the simplicity of [[Expr]], our grammar for the language
is very simple.

\begin{verbatim}
digit      ::= '0' | '1' | ... | '9'
identifier ::= digit { digit }
expr       ::= term { '|' term }
term       ::= fact { '&' term }
fact       ::= identifier
             | '(' expr ')'
             | '!' fact
\end{verbatim}


\subsection{Scanner}

We use the traditional approach of splitting scanning
and parsing.  Our scanner recognizes the 7 types of
tokens described in the enumeration [[Token]].

[[Eof]] is a token that we add at the end of the token
stream to make it easier in the parser to know when we
are done parsing.

<<type definitions>>=
#[derive(Debug, Clone, PartialOrd, PartialEq)]
enum Token {
    Eof, LParen, RParen, Ampersand, Pipe, Bang, Int(usize)
}
@

The scanning function is quite simple (again, mostly due to
the limited language); we inspect each character one at a time
and generate the appropriate token.

If the current character is one of `(', `)', `\&, `\textbar', or `!',
we emit the associated token.  If the current character is a digit, we
keep reading digits until we find a non-digit or until the end of the string.
Spaces and newlines are ignored, and reading any other character causes a panic.

<<parse functions>>=
fn scan(s: &str) -> Vec<Token> {
    let mut toks = Vec::new();
    let mut i = 0;
    let b = s.as_bytes();
    while i < b.len() {
        match b[i] {
            b'(' => { toks.push(Token::LParen); i += 1; }
            b')' => { toks.push(Token::RParen); i += 1; }
            b'&' => { toks.push(Token::Ampersand); i += 1; }
            b'|' => { toks.push(Token::Pipe); i += 1; }
            b'!' => { toks.push(Token::Bang); i += 1; }
            d if d >= b'0' && d <= b'9' => {
                let mut numeral = String::new();
                while i < b.len() && b[i] >= b'0' && b[i] <= b'9' {
                    numeral.push(b[i] as char);
                    i += 1;
                }
                let id = numeral.parse::<usize>().unwrap();
                toks.push(Token::Int(id));
            }
            d if d == b' ' || d == b'\n' => { i += 1; }
            _ => { panic!("Invalid character: {}", b[i]); }
        }
    }
    toks.push(Token::Eof);
    return toks;
}
@

Here is a simple unit test for the scanner.  If this
was a more important project, many more tests would
be required.

<<unit tests>>=
#[test]
fn test_scan() {
    use Token::*;
    use super::scan;
    assert_eq!(vec![LParen, Int(0), Pipe, Int(14), RParen,
                    Ampersand, Bang, Int(12345), Eof],
               scan("(0 | 14)&!12345"));
}
@

\subsection{Parser}

We do parsing with a simple predictive, recursive descent.
The structure [[ParserState]] will keep track of the current
state of parsing: it has a list of tokens returned by [[scan]]
from the previous section, and an index points to the current
token.  We don't need a look-ahead token.

We implement two methods on the [[ParseState]]: one to
obtain a copy of the current token, and a method to move
to the next token.

<<type definitions>>=
struct ParseState {
    tokens: Vec<Token>,
    curr: usize
}

impl ParseState {
    fn peek(&self) -> Token {
        self.tokens[self.curr].clone()
    }

    fn eat(&mut self) {
        self.curr += 1;
    }
}
@


Our parser is invoked from a static method on expressions,
[[from_str]]; this method will invoke the scanner and the
parser.

<<expression methods>>=
fn from_str(s: &str) -> Expr {
    let toks = scan(s);
    let mut state = ParseState {
        tokens: toks,
        curr: 0
    };
    return parse_expr(&mut state);
}
@

Again, thanks to the simplicity of the language, and also
because we don't need to create something very maintainable
or fast, we can use simple techniques to create our parser.
Our strategy is simple: non-terminals in the grammar are
functions, when a rule refers to a non-terminal we do a
function call, and when it refers to a terminal, we use
[[peek]] to ensure that the correct token follows and
then use [[eat]] to move to the next item.

The repetition braces are implemented with a while loop.

<<parse functions>>=
fn parse_expr(state: &mut ParseState) -> Expr {
    let mut subexprs = Vec::new();
    let t1 = parse_term(state);
    subexprs.push(t1);
    while state.peek() == Token::Pipe {
        state.eat();
        let t = parse_term(state);
        subexprs.push(t);
    }
    if subexprs.len() == 1 {
        return subexprs[0].clone();
    } else {
        return Expr::Or(subexprs);
    }
}
@

<<parse functions>>=
fn parse_term(state: &mut ParseState) -> Expr {
    let mut subexprs = Vec::new();
    let f1 = parse_factor(state);
    subexprs.push(f1);
    while state.peek() == Token::Ampersand {
        state.eat();
        let f = parse_factor(state);
        subexprs.push(f);
    }
    if subexprs.len() == 1 {
        return subexprs[0].clone();
    } else {
        return Expr::And(subexprs);
    }
}
@

<<parse functions>>=
fn parse_factor(state: &mut ParseState) -> Expr {
    match state.peek() {
        Token::Int(id) => { state.eat(); Expr::Var(id) }
        Token::LParen => {
            state.eat();
            let e = parse_expr(state);
            if state.peek() == Token::RParen {
                state.eat();
                return e;
            } else {
                panic!("unmatched parenthesis");
            }
        }
        Token::Bang => {
            state.eat();
            let f = parse_factor(state);
            return Expr::Not(Box::new(f));
        }
        t => { panic!("unexpected token {:?}", t); }
    }
}
@


Similar to the scanner, we create way too few tests
for the parser.

<<unit tests>>=
#[test]
fn test_from_str() {
    use super::Expr;
    use super::Expr::*;
    assert_eq!(Var(3), Expr::from_str("3"));
    assert_eq!(Or(vec![Var(0), Var(1)]),
        Expr::from_str("0 | 1"));
    assert_eq!(And(vec![Var(0), Var(1)]),
        Expr::from_str("0 & 1"));
    assert_eq!(Or(vec![And(vec![Var(0), Var(1)]), Var(2)]),
        Expr::from_str("0 & 1 | 2"));
    assert_eq!(Or(vec![Var(0), And(vec![Var(1), Var(2)])]),
        Expr::from_str("0 | 1 & 2"));
    assert_eq!(Not(Box::new(Not(Box::new(Var(0))))),
        Expr::from_str("!!0"));
    }
@


\section{Evaluation}

In this section we implement the method [[eval]]
for both [[Expr]] and [[CNFExpr]] given an
environment (i.e., a mapping between a variable
identifier and a true/false value).

\subsection{Expressions}

Evaluation of an [[Expr]] should be entirely
unsurprising: we perform a depth-first search,
evaluating the variables to their associated
value in [[env]] and applying the logical operators
to their sub-expressions.

<<expression methods>>=
fn eval(&self, env: &Env) -> bool {
    match *self {
        Expr::Var(c) => env.lookup(c),
        Expr::And(ref exprs) => exprs.iter().all(|expr| expr.eval(env)),
        Expr::Or(ref exprs) => exprs.iter().any(|expr| expr.eval(env)),
        Expr::Not(ref subexpr) => !subexpr.eval(env)
    }
}
@

\subsection{CNF Expressions}

The evaluation of CNF expressions is similarly simple.

<<cnf methods>>=
impl CNFExpr {
    fn eval(&self, env: &Env) -> bool {
        self.0.iter().all(|clause| clause.eval(env))
    }
}

impl CNFClause {
    fn eval(&self, env: &Env) -> bool {
        self.0.iter().any(|literal| literal.eval(env))
    }
}

impl CNFLiteral {
    fn eval(&self, env: &Env) -> bool {
        match *self {
            CNFLiteral::Var(n) => env.lookup(n),
            CNFLiteral::Not(n) => !env.lookup(n)
        }
    }
}
@

\subsection{Environments}

An environment is a mapping between variables and values.
In \emph{rtb-boolean}, the environment is a bid request:
the fields are the variable names with their associated values.
(Technically, not all the fields of a bid request are variables
since only some of them are actually exposed to the user.
See [[variables_definition/0]]).


Like before, we can simplify our prototype by having only
two values, \emph{true} and \emph{false}.  Our environment
is internally represented by a hash table mapping a \emph{usize}
to a \emph{bool}.


<<type definitions>>=
#[derive(Debug)]
struct Env(HashMap<usize, bool>);
@

We define three methods for our environment:
[[new]] to create an empty environment,
[[insert]] to add a new binding, and
[[lookup]] to find the value associated with a variable.
The [[lookup]] method panics if the variable doesn't exist.

<<type definitions>>=
impl Env {
    fn new() -> Env {
        Env(HashMap::new())
    }

    fn insert(&mut self, var: usize, val: bool) {
        self.0.insert(var, val);
    }

    fn lookup(&self, c: usize) -> bool {
        *self.0.get(&c).expect("undeclared variable")
    }
}
@


\section{Conversion to CNF}

We finally get to the point we were waiting for, converting
an expression into CNF form.  We work from the explanations found
on Professor Jason Eisner website at the following address:
\url{https://www.cs.jhu.edu/~jason/tutorials/convert-to-CNF.html}

Thanks to Rust's pattern matching, we can follow the instructions
from Prof. Eisner quite easily.

<<expression methods>>=
fn to_cnf(&self) -> CNFExpr {
    match *self {
        Expr::Var(n) => { CNFExpr::var(n) }
        Expr::Not(ref subexpr) => { <<convert not to cnf>> }
        Expr::And(ref subexprs) => { <<convert and to cnf>> }
        Expr::Or(ref subexprs) => { <<convert or to cnf>> }
    }
}
@

\subsection{Converting a \emph{not} expression}

Given a \emph{not} expression $\varphi$,
we convert it to CNF by following the
steps detailed below (reproduced from Prof. Eisner):

\begin{itemize}
\item[] If $\varphi$ has the form $\neg(...)$, then:
  \begin{itemize}
  \item If $\varphi$ has the form $\neg{A}$ for some variable $A$, then return $\varphi$.
  \item If $\varphi$ has the form $\neg(\neg P)$, then return $CONVERT(P)$. (double negation)
  \item If $\varphi$ has the form $\neg(P \wedge Q)$, then return $CONVERT(\neg P \vee \neg Q)$. (de Morgan's Law)
  \item If $\varphi$ has the form $\neg(P \vee Q)$, then return $CONVERT(\neg P \wedge \neg Q)$. (de Morgan's Law)
  \end{itemize}
\end{itemize}

<<convert not to cnf>>=
match **subexpr {
    Expr::Var(n) => CNFExpr::not(n),
    Expr::Not(ref subexpr2) => subexpr2.to_cnf(),
    Expr::And(ref subexprs) => {
        let de_morganed = de_morgan(subexprs);
        Expr::Or(de_morganed).to_cnf()
    }
    Expr::Or(ref subexprs) => {
        let de_morganed = de_morgan(subexprs);
        Expr::And(de_morganed).to_cnf()
    }
}
@

<<functions>>=
fn de_morgan(exprs: &[Expr]) -> Vec<Expr> {
    exprs
        .iter()
        .map(|x| Expr::Not(Box::new(x.clone())))
        .collect::<Vec<Expr>>()
}
@

The main difference between the instructions and our code
is that the instructions expect conjunction and disjunction
to be done on only two sub-expressions at a time.  We adapt
the instructions to support our vectors of sub-expressions.

In the head of the match expression, [[subexpr]] is dereferenced
twice: once for the borrow, once for the box.

<<unit tests>>=
#[test]
fn test_convert_not_simple() {
    use super::{CNFExpr, Expr};
    assert_eq!(CNFExpr::var(0), Expr::from_str("0").to_cnf());
    assert_eq!(CNFExpr::not(0), Expr::from_str("!0").to_cnf());
    assert_eq!(CNFExpr::var(0), Expr::from_str("!!0").to_cnf());
}
@

\subsection{Converting an \emph{and} expression}

To convert an \emph{and} expression to CNF, we
convert each sub-expression to CNF and then
concatenate their clauses into one big CNFExpr.

<<convert and to cnf>>=
let mut cnf_clauses = Vec::new();
for subexpr in subexprs {
    let subexpr_cnf = subexpr.to_cnf();
    for clause in subexpr_cnf.0 {
        cnf_clauses.push(clause)
    }
}
CNFExpr(cnf_clauses)
@

\subsection{Converting an \emph{or} expression}

Converting an \emph{or} expression to CNF
is the ``big bad'': it has the potential
to make our expression grow exponentially!
We'll implement the na√Øve approach, and
we'll revisit later if this turns out to
be too much of a problem.

Since there's a number of loops involved
in the process and that I easily lose track
of where I am at any given time, I'll split
the work into a bunch of chunks that I'll
stich together at the end.

Per Prof. Eisner, if our initial expression
$\varphi$ has the form $P \vee Q$, then
$CONVERT(P)$ must have the form
$P_1 \wedge ... \wedge P_m$,
and $CONVERT(Q)$ must have the form
$Q_1 \wedge ... \wedge Q_n$.
In our case, the disjunction can have
more than two sub-expressions, but the
principle still holds.

Let's first convert every sub-expression to CNF.
After the conversion is done, we store the
clauses of each CNF sub-expression inside a vector.

<<convert or sub-expressions to cnf>>=
let mut cnf_clauses: Vec<Vec<CNFClause>> = Vec::new();
for subexpr in subexprs {
    let subexpr_cnf = subexpr.to_cnf();
    cnf_clauses.push(subexpr_cnf.0)
}
@

Now we have to create a [[CNFExpr]] between
each pair of clauses.  For instance, if we
have the following vector of clauses:

\begin{verbatim}
[ [C1, C2], [C3, C4, C5], [C6] ]
\end{verbatim}

We need to create the following conjunction:

\begin{verbatim}
    (C1 or C3) and (C1 or C4) and (C1 or C5) and (C1 or C6)
and (C2 or C3) and (C2 or C4) and (C2 or C5) and (C2 or C6)
and (C3 or C6) and (C4 or C6) and (C5 or C6)
\end{verbatim}

<<create large conjunction>>=
let mut new_clauses = Vec::new();
for c1 in 0 .. cnf_clauses.len() {
    for i in 0 .. cnf_clauses[c1].len() {
        for c2 in c1+1 .. cnf_clauses.len() {
            for j in 0 .. cnf_clauses[c2].len() {
                let p = cnf_clauses[c1][i].clone();
                let q = cnf_clauses[c2][j].clone();
                let mut combined: Vec<CNFLiteral> = Vec::new();
                combined.extend(p.0);
                combined.extend(q.0);
                new_clauses.push(CNFClause(combined));
            }
        }
    }
}
CNFExpr(new_clauses)
@


<<convert or to cnf>>=
<<convert or sub-expressions to cnf>>
<<create large conjunction>>
@


\section{Experiments}

In this section, we will define a number of
experiments that can be run on a stream of
expressions.  The results should be useful
to determine if the approach is viable.

Each experiment is a function that will
consume its input from [[stdin]] and output
its results on [[stdout]].

\subsection{Parsing and conversion}

Let's first make sure that we can properly parse expressions and
convert them to conjunctive normal form.  We read a line, parse it
into an [[Expr]], and convert to a [[CNFExpr]].  We let the program
panic if there is an error, and if we parsed everything successfully
we silently exit.

<<functions>>=
fn exp_parse_and_convert() {
    let stdin = io::stdin();
    let mut buf = String::new();

    while stdin.read_line(&mut buf).unwrap() > 0 {
        let expr = Expr::from_str(&buf);
        expr.to_cnf();
        buf.clear();
    }
}
@

\subsection{Size difference}

Converting from a regular expression to
a CNF expression can cause the number of
variable references to grow exponentially.

This experiment creates a distribution map:
the difference in the number of variables in
an expression and its CNF conversion is tallied
and the totals are displayed at the end.

We use a [[BTreeMap]] to record the tallies
because it is more convenient than a [[HashMap]]:
a [[BTreeMap]] iterates over its keys in order
and so it's easier to read the results.

<<functions>>=
fn exp_size_diff() {
    let stdin = io::stdin();
    let mut buf = String::new();
    let mut tallies: BTreeMap<usize, usize> = BTreeMap::new();
    let mut total_count: usize = 0;

    while stdin.read_line(&mut buf).unwrap() > 0 {
        let expr = Expr::from_str(&buf);
        let cnf = expr.to_cnf();
        let diff = cnf.size() - expr.size();
        let tally = tallies.entry(diff).or_insert(0);
        *tally += 1;
        total_count += 1;
        buf.clear();
    }

    for (k, v) in tallies {
        println!("{} {} ({:.2}%)", k, v, (v as f64 / total_count as f64) * 100.0);
    }
}
@

\subsection{Evaluation (correctness)}

The Rust type checker accepts [[to_cnf]],
meaning tht we produce an expression that
is truly in CNF form.  However, this
doesn't mean that the construction retains
the semantics of the original expression.

In this sub-section, we create an
experiment to give us greater confidence
that the conversion isn't buggy.
We convert an expression to its CNF form
and evaluate both with many randomly generated environments.

If there is a discrepancy between the results,
we know that there is a bug in our implementation.
If that happens, we output the line number of
the culprit and the environment that caused the error.

If there is no discrepancy between the results,
there may still be a bug in the code, but at least we can
feel more confident in our implementation.

\paragraph{Environment generation}
We first need to create random environments.
We shall proceed in two steps:
(1) we'll find all the variable ids used in an expression,
(2) we will insert them in an environment with a random boolean value.

<<expression methods>>=
fn vars(&self, vars: &mut HashSet<usize>) {
    match *self {
        Expr::Var(n) => { vars.insert(n); }
        Expr::Not(ref sub) => { sub.vars(vars); }
        Expr::Or(ref subs)
        | Expr::And(ref subs) => {
            for sub in subs {
                sub.vars(vars);
            }
        }
    }
}
@

<<type definitions>>=
impl Env {
    fn random(vars: &HashSet<usize>) -> Env {
        let mut rng = rand::thread_rng();
        let mut env = Env::new();
        for var in vars {
            env.insert(*var, rng.gen::<bool>());
        }
        return env;
    }
}
@

\paragraph{Simulation}
With our helper functionality in place,
all that's left to do is throw a lot of
environments at the expressions and
hope they evaluate to the same value.

<<functions>>=
fn exp_eval_correctness() {
    let stdin = io::stdin();
    let mut buf = String::new();
    let mut line = 1;

    while stdin.read_line(&mut buf).unwrap() > 0 {
        let expr = Expr::from_str(&buf);
        let cnf = expr.to_cnf();

        let mut vars = HashSet::new();
        expr.vars(&mut vars);
        for _ in 0 .. EVAL_ITER {
            let env = Env::random(&vars);
            let v1 = expr.eval(&env);
            let v2 = cnf.eval(&env);
            if v1 != v2 {
                println!("Error (line {}): {:?}", line, env);
                return;
            }
        }

        buf.clear();
        line += 1;
    }
}
@


\subsection{Evaluation (speed)}

After asserting that raw expressions and their CNF versions evaluate
to the same result, we want to know about the difference in evaluation
speed.

\subsubsection{Histogram}

Before we write the code to do the speed measurements, let's think about
how we want to display the results of those measurements.  A histogram
seems ideal given the large number of expressions in our set.
The histogram will help give us a general idea by telling us
how many ratios between the time to evaluate the original expression and
the time to evaluate the CNF expression fall between 0\% and 10\%,
between 10\% and 20\%, etc.

Let's create a [[Histogram]] structure for this purpose.

<<type definitions>>=
struct Histogram {
    num_windows: usize,
    buckets: Vec<usize>
}

impl Histogram {
    <<histogram methods>>
}
@

The [[num_windows]] field controls how many buckets the
histogram contains, and thus the range of each bucket.
For example, if [[num_window]] is 2, there will be three
buckets: one for ratios in the range $[0, 0.5[$, one for
ratios in the range $[0.5, 1.0[$, and one for $[1.0, +\infty[$.
The tally of ratios for each range window is contained
in the vector [[buckets]].

\paragraph{Creating a histogram}
To create a histogram, the user invokes the [[new]]
method, specifying the number of windows he wants.

<<histogram methods>>=
fn new(num_windows: usize) -> Histogram {
    Histogram {
        num_windows: num_windows,
        buckets: iter::repeat(0).take(num_windows + 1).collect()
    }
}
@

\paragraph{Tallying}
We tally a ratio by computing which bucket the parameter belongs to
and increasing that bucket by one.

The formula to determine the appropriate bucket for a ratio $r$ is as follows:

\[
bucket(r) = min\left( \lfloor{r \cdot \text{[[num_windows]]}}\rfloor,
\text{[[num_windows]]} \right)
\]

<<histogram methods>>=
fn tally(&mut self, r: f64) {
    let x = (r * self.num_windows as f64) as usize;
    let idx = cmp::min(x, self.num_windows);
    self.buckets[idx] += 1;
}
@

\paragraph{Unit tests}
Let's test our [[Histogram]] by create a simple one and
performing a few manual tallies.

<<unit tests>>=
#[test]
fn test_histogram() {
    use super::Histogram;
    let mut h = Histogram::new(4);
    h.tally(0.1);
    h.tally(0.3);
    h.tally(0.6);
    h.tally(0.9);
    h.tally(1.2);
    assert_eq!(1, h.buckets[0]);
    assert_eq!(1, h.buckets[1]);
    assert_eq!(1, h.buckets[2]);
    assert_eq!(1, h.buckets[3]);
    assert_eq!(1, h.buckets[4]);
}
@

\paragraph{Printing}
We'll finish our [[Histogram]] struct by writing a
method to print the results to stdout.

<<histogram methods>>=
fn display(&self) {
    let slice = 1.0 / (self.num_windows as f64);
    for i in 0 .. self.num_windows {
        println!("{:.2} .. {:.2} : {}",
            slice * (i as f64),
            slice * ((i+1) as f64),
            self.buckets[i]);
    }
    println!("1.00 .. +inf : {}", self.buckets[self.num_windows]);
}
@

\subsubsection{Benchmarking}

With our [[Histogram]] struct in place, we are ready to
take our time measurements.  We will use Rust's [[Instant]]
struct for that purpose.

We will evaluate each expression [[EVAL_ITER]] times, and tally the
ratio between the time taken by the vanilla expression over the
time taken by the CNF expression.

<<functions>>=
fn exp_eval_speed() {
    let stdin = io::stdin();
    let mut buf = String::new();
    let mut h = Histogram::new(10);

    while stdin.read_line(&mut buf).unwrap() > 0 {
        let expr = Expr::from_str(&buf);
        let cnf = expr.to_cnf();
        let mut vars = HashSet::new();
        expr.vars(&mut vars);
        let mut vanilla_time = 0;
        let mut cnf_time = 0;

        for _ in 0 .. EVAL_ITER {
            let env = Env::random(&vars);
            let now = Instant::now();
            expr.eval(&env);
            let elapsed = now.elapsed();
            vanilla_time += elapsed.as_secs() + (elapsed.subsec_nanos() as u64);

            let now = Instant::now();
            cnf.eval(&env);
            let elapsed = now.elapsed();
            cnf_time += elapsed.as_secs() + (elapsed.subsec_nanos() as u64);

        }

        //let ratio = (vanilla_time as f64) / (cnf_time as f64);
        let ratio = (cnf_time as f64) / (vanilla_time as f64);
        h.tally(ratio);

        buf.clear();
    }

    h.display();
}
@



\section{Putting it all together}

<<cnf.rs>>=
extern crate rand;

use std::cmp;
use std::collections::{HashSet, BTreeMap, HashMap};
use std::env;
use std::fmt;
use std::io;
use std::iter;
use std::process;
use std::time::{Instant};

use rand::Rng;

const EVAL_ITER: usize = 10_000;

<<type definitions>>
<<parse functions>>
<<functions>>

#[cfg(not(test))]
fn main() {
    let args = env::args().collect::<Vec<String>>();
    if args.len() == 1 {
        usage();
    }
    if args[1] == "parse" {
        exp_parse_and_convert();
    } else if args[1] == "diff" {
        exp_size_diff();
    } else if args[1] == "eval" {
        exp_eval_correctness();
    } else if args[1] == "bench" {
        exp_eval_speed();
    }
}

fn usage() -> ! {
    println!("usage: cnf <parse | diff | eval | bench>");
    process::exit(1);
}
@

\section{Erlang}

In this section we define an Erlang module
with a number of utility functions from
reading the flights from a [[.bert]] file,
extracting the expressions, parsing them,
replacing the literals with variables, etc.

<<cnf.erl>>=
-module(cnf).

-include_lib("rtb_boolean/include/rtb_boolean.hrl").

-compile(export_all).

read_flights(PathName) ->
    {ok, Bin} = file:read_file(PathName),
    [{flights, Entries} | _] = binary_to_term(Bin),
    [Fields || {_Id, Fields} <- Entries].

extract_expressions(Flights) ->
    [element(2, lists:keyfind(boolean_expression, 1, Flight))
    || Flight <- Flights].

parse(Expressions) ->
    lists:map(
        fun(E) ->
            {ok, Tokens, _} = rtb_boolean_lexer:string(binary_to_list(E)),
            {ok, Ast} = rtb_boolean_parser:parse(Tokens),
            Ast
        end,
        Expressions).

deliteralize_asts(Asts) ->
    lists:foldl(fun(Ast, {AccAsts, Map, Next}) ->
        {Ast2, Map2, Next2} = deliteralize(Ast, Map, Next),
        {[Ast2 | AccAsts], Map2, Next2}
    end, {[], #{}, 0}, Asts).

deliteralize_list(Exprs, Map, Next) ->
    lists:foldl(fun(Expr, {AccExprs, M, N}) ->
        {Expr2, M2, N2} = deliteralize(Expr, M, N),
        {[Expr2 | AccExprs], maps:merge(M, M2), N2}
    end, {[], Map, Next}, Exprs).

deliteralize({ast_and, Exprs}, Map, Next) ->
    {Exprs2, Map2, Next2} = deliteralize_list(Exprs, Map, Next),
    {{ast_and, Exprs2}, Map2, Next2};

deliteralize({ast_or, Exprs}, Map, Next) ->
    {Exprs2, Map2, Next2} = deliteralize_list(Exprs, Map, Next),
    {{ast_or, Exprs2}, Map2, Next2};

deliteralize({ast_not, Expr}, Map, Next) ->
    {Expr2, Map2, Next2} = deliteralize(Expr, Map, Next),
    {{ast_not, Expr2}, Map2, Next2};

deliteralize(AstNode, Map, Next) ->
    case maps:find(AstNode, Map) of
        {ok, {VarNode, Count}} ->
            Map2 = maps:put(AstNode, {VarNode, Count+1}, Map),
            {VarNode, Map2, Next};
        error ->
            VarNode = {ast_variable, undefined, integer_to_list(Next)},
            Map2 = maps:put(AstNode, {VarNode, 1}, Map),
            {VarNode, Map2, Next + 1}
    end.

intersperse([], _) -> [];
intersperse([X], _) -> [X];
intersperse([X, Y | Rest], Sep) -> [X, Sep | intersperse([Y | Rest], Sep)].

pp({ast_and, Exprs}) ->
    [$(, intersperse(lists:map(fun pp/1, Exprs), " & "), $)];
pp({ast_or, Exprs}) ->
    [$(, intersperse(lists:map(fun pp/1, Exprs), " | "), $)];
pp({ast_not, Expr}) ->
    [$!, $(, pp(Expr), $)];
pp({ast_variable, _, N}) ->
    N.


dump(DeliteralizedAsts, Path) ->
    {ok, Fd} = file:open(Path, [write]),
    lists:foreach(fun(Ast) ->
        file:write(Fd, pp(Ast)),
        file:write(Fd, "\n")
    end, DeliteralizedAsts),
    file:close(Fd).

@


\begin{appendices}

\section{}

In this appendix, we list all the unit tests that were used
to ensure that the program worked as expected.

<<cnf.rs>>=
#[cfg(test)]
mod test {
    use Env;
    fn make_env(bools: &[usize]) -> Env {
        let mut e = Env::new();
        for (i, b) in bools.iter().enumerate() {
            e.0.insert(i, if *b == 0 { false } else { true });
        }
        return e;
    }

    <<unit tests>>
}
@


<<unit tests>>=
<<expression evaluation tests>>
@


<<expression evaluation tests>>=
#[test]
fn test_eval() {
    use Expr::*;
    let e1 = And(vec![Var(0), Var(1), Var(2)]);
    assert_eq!(false, e1.eval(&make_env(&vec![0, 0, 0])));
    assert_eq!(false, e1.eval(&make_env(&vec![0, 0, 1])));
    assert_eq!(false, e1.eval(&make_env(&vec![0, 1, 0])));
    assert_eq!(false, e1.eval(&make_env(&vec![0, 1, 1])));
    assert_eq!(false, e1.eval(&make_env(&vec![1, 0, 0])));
    assert_eq!(false, e1.eval(&make_env(&vec![1, 0, 1])));
    assert_eq!(false, e1.eval(&make_env(&vec![1, 1, 0])));
    assert_eq!(true , e1.eval(&make_env(&vec![1, 1, 1])));

    let e2 = Or(vec![Var(0), Var(1), Var(2)]);
    assert_eq!(false, e2.eval(&make_env(&vec![0, 0, 0])));
    assert_eq!(true , e2.eval(&make_env(&vec![0, 0, 1])));
    assert_eq!(true , e2.eval(&make_env(&vec![0, 1, 0])));
    assert_eq!(true , e2.eval(&make_env(&vec![0, 1, 1])));
    assert_eq!(true , e2.eval(&make_env(&vec![1, 0, 0])));
    assert_eq!(true , e2.eval(&make_env(&vec![1, 0, 1])));
    assert_eq!(true , e2.eval(&make_env(&vec![1, 1, 0])));
    assert_eq!(true , e2.eval(&make_env(&vec![1, 1, 1])));
}
@


\end{appendices}

\end{document}
