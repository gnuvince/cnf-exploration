\documentclass{article}

\usepackage{noweb}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[colorlinks,linkcolor=blue]{hyperref}
\usepackage{parskip}
\usepackage{microtype}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage[titletoc,title]{appendix}

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\newcommand{\exprref}[1]{Expression~\ref{#1}}

\title{Exploiting CNF Common Clauses for Faster Evaluation}
\author{Vincent Foley}

\begin{document}

\maketitle

\begin{abstract}
\noindent
We show how representing boolean expressions in conjunctive-normal form (CNF)
allows for an evaluation strategy that
(1) avoids unnecessarily recomputing common clauses, and
(2) can avoid evaluating an expression if one of its clauses has already failed.
\end{abstract}

\section{Introduction}

The core task of \emph{rtb-boolean} is to return a list of flight ids that
match the parameters of a bid request%
\footnote{Other objects such as products and usegments use the same
infrastructure, but to make this document
less verbose and more concrete,
we'll specifically concentrate on flights.}%
.

The current evaluation strategy is simple:
for every flight, we evaluate its associated boolean expression using
the fields and values from the incoming bid request.
If the evaluation succeeds, we record the flight's id in a list of matches.
This strategy is captured in [[<<find matches naively>>]].
In addition to its simplicity, an advantage of this technique
is that it does not require that the
boolean expressions have a specific structure; any combination
of the operators \emph{and}, \emph{or}, and \emph{not} is acceptable.

<<find matches naively>>=
fn find_matches(bid_request, flights):
    matches := []
    for i := 0 to len(flights) do
        if eval(bid_request, flights[i].expr) then
            matches.add(i)
    done
    return matches
@

The main weakness of this approach is that it considers expressions in
isolation; it does not attempt to exploit the shared environment (the bid
request) nor the fact that a sub-expression may be shared among
multiple flights.

% More vigorous
To address this weakness, we reformulate the boolean expressions into
CNF and exploit that structure to perform fewer evaluations.

\subsection{Conjunctive-normal form}

An expression is in conjunctive-normal form if it is
a conjunction of clauses;
a clause is a disjunction of literals;
a literal is either a variable or
the negation of a literal.

In the examples below, \exprref{eq:cnf} is in CNF
because it has three clauses joined by conjuctions, and
none of the clauses uses the conjunctive operator.
\exprref{eq:not-cnf-1} uses conjunction in one of
its sub-expressions, and the clauses of \exprref{eq:not-cnf-2}
are not all joined by conjunctions, and thus neither is in CNF.
We may think that \exprref{eq:not-cnf-3} is in CNF,
however the negation of a clause is not a clause,
and therefore it is not in CNF.

\begin{align}
  \text{\cmark} \quad & X \wedge (Y \vee Z) \wedge \neg W   \label{eq:cnf} \\
  \text{\xmark} \quad & X \wedge (Y \wedge Z) \wedge \neg W \label{eq:not-cnf-1} \\
  \text{\xmark} \quad & X \wedge (Y \wedge Z) \vee \neg W   \label{eq:not-cnf-2} \\
  \text{\xmark} \quad & X \wedge (Y \vee Z) \wedge \neg (W \vee X \vee Y)   \label{eq:not-cnf-3}
\end{align}

\subsection{CNF-aware matching}

If the boolean expressions are in conjunctive-normal form,
we can leverage their common structure to improve our matching strategy.
We can evaluate an expression clause by clause:
the failure of a single clause causes the entire expression to fail.
In fact, if a clause $X$ fails, it causes \emph{all} expressions
that contain $X$ to also fail.

In the example below, the expressions share a clause, $X$.
If during the evaluation of \exprref{eq:expr1}
we find that $X = \text{\it false}$,
then we don't need to evaluate any of the other clauses of \exprref{eq:expr1}.
Also, because $X$ is a clause in \exprref{eq:expr2},
the clauses $F \vee G$, and $\neg H$ will never
need to be evaluated.

\begin{align}
    X \wedge (A \vee B) \wedge C        \label{eq:expr1} \\
    (F \vee G) \wedge X \wedge \neg H   \label{eq:expr2}
\end{align}

We hope that skipping clauses in this
way will yield an appreciable speed-up over the na√Øve approach.

\subsection{Implementation}

We will implement a prototype of CNF-aware matching using Rust.
We use Rust for two main reasons: (1) being compiled to machine
code with LLVM, it should give us a fairer assessment of the
performance we can expect when we do the implementation in C;
(2) Rust provides a number of language features that should
help make this prototype easier to write (e.g., enums and
pattern matching) and harder to get wrong (e.g., static
type checking and borrow checking).

\section{Data structures}

In this section, we define the data structure to represent
boolean expressions.

\subsection{Expressions}
\label{sec:expressions}

We first define expressions that are \textbf{not} expected to be in
conjunctive-normal form: they represent the expressions as written by
users.  A later section will automate the conversion to CNF.

To simplify the prototype, we intentionally gut the boolean language
to only 4 constructs, which are described in the enum [[Expr]].
In a complete implementation, we would also have numbers, strings,
comparisons, list operations (\emph{all of}, \emph{not in}, etc.),
and function calls.  All these operation would be leaves of the
expression tree, and thus literals; this is why we allow
ourselves only to have one node type (\emph{Var}) as a representative
of literals.

<<type definitions>>=
#[derive(Debug, PartialOrd, PartialEq, Clone)]
enum Expr {
    Var(usize),     // Variables are distinguished by a numeric id
    And(Vec<Expr>), // The conjunction of multiple expressions
    Or(Vec<Expr>),  // The disjunction of multiple expression
    Not(Box<Expr>)  // The negation of an expression
}

impl Expr {
    <<expression methods>>
}
@

\subsection{CNF Expressions}

Let us also define data structures for CNF expressions.
The [[Expr]] enum defined above could be used to represent
a CNF expression, but it does not enforce that an expression
be in conjunctive-normal form.
By defining a type for CNF expressions, CNF clauses, and
literals, we can make sure that it is impossible to even
construct an expression that is not in CNF.

<<type definitions>>=
#[derive(Debug, PartialOrd, Ord, PartialEq, Eq, Hash, Clone)]
struct CNFExpr(Vec<CNFClause>);

#[derive(Debug, PartialOrd, Ord, PartialEq, Eq, Hash, Clone)]
struct CNFClause(Vec<CNFLiteral>);

#[derive(Debug, PartialOrd, Ord, PartialEq, Eq, Hash, Clone)]
enum CNFLiteral {
    Var(usize),
    Not(usize)
}

<<cnf methods>>
@

\paragraph{Simple constructors}
Creating a CNF Expression structure by hand isn't hard,
but it's certainly verbose.  In the next chunk, we introduce
two constructors that are going to simplify some down the line:
[[var]] to create a CNF expression of a single variable, and
[[not]] to create the negation of a single variable.

<<cnf methods>>=
impl CNFExpr {
    fn var(n: usize) -> CNFExpr {
        CNFExpr(vec![CNFClause(vec![CNFLiteral::Var(n)])])
    }

    fn not(n: usize) -> CNFExpr {
        CNFExpr(vec![CNFClause(vec![CNFLiteral::Not(n)])])
    }
}
@

\subsection{Utility methods}

In this subsection we'll implement a number of utility methods
on expressions and CNF expressions.

\paragraph{Display}
Our first order of business is to provide a way to print expressions;
the default format of [[Debug]] quickly gets unreadble
with all the extra boxes and vectors.  We implement the [[Display]]
trait for expressions and for CNF expressions.  We also
deactivate the warnings that are triggered by not using the
result of the [[write!]] macro.

<<functions>>=
impl fmt::Display for Expr {
    #[allow(unused_must_use)]
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match *self {
            Expr::Var(n) => { write!(f, "{}", n) }
            Expr::Not(ref sub) => { write!(f, "!{}", sub) }
            Expr::And(ref subs) => {
                let mut first = true;
                write!(f, "(");
                for sub in subs {
                    if !first { write!(f, " & "); }
                    first = false;
                    write!(f, "{}", sub);
                }
                write!(f, ")")
            }
            Expr::Or(ref subs) => {
                let mut first = true;
                write!(f, "(");
                for sub in subs {
                    if !first { write!(f, " | "); }
                    first = false;
                    write!(f, "{}", sub);
                }
                write!(f, ")")
            }
        }
    }
}
@

<<unit tests>>=
#[test]
fn test_expr_display() {
    use super::Expr;
    assert_eq!("0", format!("{}", Expr::from_str("0")));
    assert_eq!("!0", format!("{}", Expr::from_str("!0")));
    assert_eq!("(0 & 1)", format!("{}", Expr::from_str("0 & 1")));
    assert_eq!("(0 | 1)", format!("{}", Expr::from_str("0 | 1")));
    assert_eq!("(0 | (1 & 2))", format!("{}", Expr::from_str("0 | 1 & 2")));
}
@


<<functions>>=
impl fmt::Display for CNFExpr {
    #[allow(unused_must_use)]
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if self.0.len() == 0 { write!(f, "") }
        else if self.0.len() == 1 { write!(f, "{}", self.0[0]) }
        else {
            let mut first = true;
            for clause in &self.0 {
                if !first { write!(f, " & "); }
                write!(f, "{}", clause);
                first = false;
            }
            write!(f, "")
        }
    }
}

impl fmt::Display for CNFClause {
    #[allow(unused_must_use)]
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if self.0.len() == 0 { write!(f, "") }
        else if self.0.len() == 1 { write!(f, "{}", self.0[0]) }
        else {
            write!(f, "(");
            let mut first = true;
            for clause in &self.0 {
                if !first { write!(f, " | "); }
                write!(f, "{}", clause);
                first = false;
            }
            write!(f, ")")
        }
    }
}

impl fmt::Display for CNFLiteral {
    #[allow(unused_must_use)]
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match *self {
            CNFLiteral::Var(n) => write!(f, "{}", n),
            CNFLiteral::Not(n) => write!(f, "!{}", n)
        }
    }
}
@

<<unit tests>>=
#[test]
fn test_cnf_display() {
    use super::{CNFExpr, CNFClause, CNFLiteral};
    assert_eq!("", format!("{}", CNFExpr(vec!())));
    assert_eq!("0", format!("{}", CNFExpr::var(0)));
    assert_eq!("!0", format!("{}", CNFExpr::not(0)));
    assert_eq!("(0 | 1)", format!("{}",
        CNFExpr(vec!(CNFClause(vec!(CNFLiteral::Var(0),
                                    CNFLiteral::Var(1)))))));
    assert_eq!("(0 | 1) & !2", format!("{}",
        CNFExpr(vec!(CNFClause(vec!(CNFLiteral::Var(0),
                                    CNFLiteral::Var(1))),
                     CNFClause(vec!(CNFLiteral::Not(2)))))));
}
@

\paragraph{Expression size}
Next, we implement a method to return the size of
an expression or a CNF expression.  The size is
the number of variables used in the expression.
This is a useful metric to have:
some of the conversion rules to CNF create
duplicates of some variables (this is especially
true in the handling of the \emph{or} operator),
and the size of the CNF expression can be
exponentially larger.

<<expression methods>>=
fn size(&self) -> usize {
    match *self {
        Expr::Var(_) => 1,
        Expr::Not(ref subexpr) => subexpr.size(),
        Expr::Or(ref subexprs)
        | Expr::And(ref subexprs) => subexprs.iter().map(|x| x.size()).sum()
    }
}
@

<<unit tests>>=
#[test]
fn test_size() {
    use super::Expr;
    assert_eq!(0, Expr::Or(vec![]).size());
    assert_eq!(0, Expr::And(vec![]).size());
    assert_eq!(1, Expr::from_str("0").size());
    assert_eq!(1, Expr::from_str("!0").size());
    assert_eq!(2, Expr::from_str("!0 & 1").size());
    assert_eq!(2, Expr::from_str("!0 | !1").size());
}
@


<<cnf methods>>=
impl CNFExpr {
    fn size(&self) -> usize {
        self.0.iter().map(|clause| clause.size()).sum()
    }
}

impl CNFClause {
    fn size(&self) -> usize {
        self.0.len()
    }
}
@



\section{Parsing}

Even simple expressions can become long and hard to understand
if we only use the Rust syntax to read and write them.
To alleviate this task, we create a small parser that can read
expressions as strings and generate the equivalent [[Expr]] structure.
This parser will also allow us to read expressions
from disk.

Thanks to the simplicity of [[Expr]], our grammar for the language
is very simple.

\begin{verbatim}
digit      ::= '0' | '1' | ... | '9'
identifier ::= digit { digit }
expr       ::= term { '|' term }
term       ::= fact { '&' term }
fact       ::= identifier
             | '(' expr ')'
             | '!' fact
\end{verbatim}


\subsection{Scanner}

We use the traditional approach of splitting scanning
and parsing.  Our scanner recognizes the 7 types of
tokens described in the enumeration [[Token]].

[[Eof]] is a token that we add at the end of the token
stream to make it easier in the parser to know when we
are done parsing.

<<type definitions>>=
#[derive(Debug, Clone, PartialOrd, PartialEq)]
enum Token {
    Eof, LParen, RParen, Ampersand, Pipe, Bang, Int(usize)
}
@

The scanning function is quite simple (again, mostly due to
the limited language); we inspect each character one at a time
and generate the appropriate token.

If the current character is one of `(', `)', `\&, `\textbar', or `!',
we emit the associated token.  If the current character is a digit, we
keep reading digits until we find a non-digit or until the end of the string.
Spaces and newlines are ignored, and reading any other character causes a panic.

<<parse functions>>=
fn scan(s: &str) -> Vec<Token> {
    let mut toks = Vec::new();
    let mut i = 0;
    let b = s.as_bytes();
    while i < b.len() {
        match b[i] {
            b'(' => { toks.push(Token::LParen); i += 1; }
            b')' => { toks.push(Token::RParen); i += 1; }
            b'&' => { toks.push(Token::Ampersand); i += 1; }
            b'|' => { toks.push(Token::Pipe); i += 1; }
            b'!' => { toks.push(Token::Bang); i += 1; }
            d if d >= b'0' && d <= b'9' => {
                let mut numeral = String::new();
                while i < b.len() && b[i] >= b'0' && b[i] <= b'9' {
                    numeral.push(b[i] as char);
                    i += 1;
                }
                let id = numeral.parse::<usize>().unwrap();
                toks.push(Token::Int(id));
            }
            d if d == b' ' || d == b'\n' => { i += 1; }
            _ => { panic!("Invalid character: {}", b[i]); }
        }
    }
    toks.push(Token::Eof);
    return toks;
}
@

Here is a simple unit test for the scanner.  If this
was a more than a prototype project, many more tests would
be required.

<<unit tests>>=
#[test]
fn test_scan() {
    use Token::*;
    use super::scan;
    assert_eq!(vec![LParen, Int(0), Pipe, Int(14), RParen,
                    Ampersand, Bang, Int(12345), Eof],
               scan("(0 | 14)&!12345"));
}
@

\subsection{Parser}

We do parsing with a predictive, recursive descent.
The structure [[ParserState]] will keep track of the current
state of parsing: it has a list of tokens returned by [[scan]]
from the previous section, and an index points to the current
token.  We don't need a look-ahead token.

We implement two methods on the [[ParseState]]: one to
obtain a copy of the current token, and a method to move
to the next token.

<<type definitions>>=
struct ParseState {
    tokens: Vec<Token>,
    curr: usize
}

impl ParseState {
    fn peek(&self) -> Token {
        self.tokens[self.curr].clone()
    }

    fn eat(&mut self) {
        self.curr += 1;
    }
}
@


Our parser is invoked from a static method on expressions,
[[from_str]]; this method will invoke the scanner and the
parser.

<<expression methods>>=
fn from_str(s: &str) -> Expr {
    let toks = scan(s);
    let mut state = ParseState {
        tokens: toks,
        curr: 0
    };
    return parse_expr(&mut state);
}
@

Again, thanks to the simplicity of the language, and also
because we don't need to create something very maintainable
or fast, we can use simple techniques to create our parser.
Our strategy is simple: non-terminals in the grammar are
functions; when a rule refers to a non-terminal we do a
function call; when a rule refers to a terminal, we use
[[peek]] to ensure that the correct token follows and
then use [[eat]] to move to the next item.

The repetition braces are implemented with a while loop.

<<parse functions>>=
fn parse_expr(state: &mut ParseState) -> Expr {
    let mut subexprs = Vec::new();
    let t1 = parse_term(state);
    subexprs.push(t1);
    while state.peek() == Token::Pipe {
        state.eat();
        let t = parse_term(state);
        subexprs.push(t);
    }
    if subexprs.len() == 1 {
        return subexprs[0].clone();
    } else {
        return Expr::Or(subexprs);
    }
}
@

<<parse functions>>=
fn parse_term(state: &mut ParseState) -> Expr {
    let mut subexprs = Vec::new();
    let f1 = parse_factor(state);
    subexprs.push(f1);
    while state.peek() == Token::Ampersand {
        state.eat();
        let f = parse_factor(state);
        subexprs.push(f);
    }
    if subexprs.len() == 1 {
        return subexprs[0].clone();
    } else {
        return Expr::And(subexprs);
    }
}
@

<<parse functions>>=
fn parse_factor(state: &mut ParseState) -> Expr {
    match state.peek() {
        Token::Int(id) => { state.eat(); Expr::Var(id) }
        Token::LParen => {
            state.eat();
            let e = parse_expr(state);
            if state.peek() == Token::RParen {
                state.eat();
                return e;
            } else {
                panic!("unmatched parenthesis");
            }
        }
        Token::Bang => {
            state.eat();
            let f = parse_factor(state);
            return Expr::Not(Box::new(f));
        }
        t => { panic!("unexpected token {:?}", t); }
    }
}
@


Similar to the scanner, we create way too few tests
for the parser.

<<unit tests>>=
#[test]
fn test_from_str() {
    use super::Expr;
    use super::Expr::*;
    assert_eq!(Var(3), Expr::from_str("3"));
    assert_eq!(Or(vec![Var(0), Var(1)]),
        Expr::from_str("0 | 1"));
    assert_eq!(And(vec![Var(0), Var(1)]),
        Expr::from_str("0 & 1"));
    assert_eq!(Or(vec![And(vec![Var(0), Var(1)]), Var(2)]),
        Expr::from_str("0 & 1 | 2"));
    assert_eq!(Or(vec![Var(0), And(vec![Var(1), Var(2)])]),
        Expr::from_str("0 | 1 & 2"));
    assert_eq!(Not(Box::new(Not(Box::new(Var(0))))),
        Expr::from_str("!!0"));
    }
@


\section{Evaluation}

In this section we implement the method [[eval]]
for both [[Expr]] and [[CNFExpr]] given an
environment (i.e., a mapping between a variable
identifier and a true/false value).

\subsection{Expressions}

Evaluation of an [[Expr]] should be entirely
unsurprising: we perform a depth-first search,
evaluating the variables to their associated
value in [[env]] and applying the logical operators
to their sub-expressions.

<<expression methods>>=
fn eval(&self, env: &Env) -> bool {
    match *self {
        Expr::Var(c) => env.lookup(c),
        Expr::And(ref exprs) => exprs.iter().all(|expr| expr.eval(env)),
        Expr::Or(ref exprs) => exprs.iter().any(|expr| expr.eval(env)),
        Expr::Not(ref subexpr) => !subexpr.eval(env)
    }
}
@

\subsection{CNF Expressions}

The evaluation of CNF expressions is similarly simple.

<<cnf methods>>=
impl CNFExpr {
    fn eval(&self, env: &Env) -> bool {
        self.0.iter().all(|clause| clause.eval(env))
    }
}

impl CNFClause {
    fn eval(&self, env: &Env) -> bool {
        self.0.iter().any(|literal| literal.eval(env))
    }
}

impl CNFLiteral {
    fn eval(&self, env: &Env) -> bool {
        match *self {
            CNFLiteral::Var(n) => env.lookup(n),
            CNFLiteral::Not(n) => !env.lookup(n)
        }
    }
}
@

\subsection{Environments}

An environment is a mapping between variables and values.
In \emph{rtb-boolean}, the environment is a bid request:
the fields are the variable names with their associated values.
(Technically, not all the fields of a bid request are variables
since only some of them are actually exposed to the user.
See [[variables_definition/0]]).


Like before, we can simplify our prototype by having only
two values, \emph{true} and \emph{false}.  Our environment
is internally represented by a hash table mapping a \emph{usize}
to a \emph{bool}.


<<type definitions>>=
#[derive(Debug)]
struct Env(HashMap<usize, bool>);
@

We define three methods for our environment:
[[new]] to create an empty environment,
[[insert]] to add a new binding, and
[[lookup]] to find the value associated with a variable.
The [[lookup]] method panics if the variable doesn't exist.

<<type definitions>>=
impl Env {
    fn new() -> Env {
        Env(HashMap::new())
    }

    fn insert(&mut self, var: usize, val: bool) {
        self.0.insert(var, val);
    }

    fn lookup(&self, c: usize) -> bool {
        *self.0.get(&c).expect("undeclared variable")
    }
}
@


\section{Conversion to CNF}

We finally get to the point we were waiting for, converting
an expression into CNF form.  We work from the explanations found
on Professor Jason Eisner website at the following address:
\url{https://www.cs.jhu.edu/~jason/tutorials/convert-to-CNF.html}

Thanks to Rust's pattern matching, we can follow the instructions
from Prof. Eisner quite easily.

<<expression methods>>=
fn to_cnf(&self) -> CNFExpr {
    match *self {
        Expr::Var(n) => { CNFExpr::var(n) }
        Expr::Not(ref subexpr) => { <<convert not to cnf>> }
        Expr::And(ref subexprs) => { <<convert and to cnf>> }
        Expr::Or(ref subexprs) => { <<convert or to cnf>> }
    }
}
@

\subsection{Converting a \emph{not} expression}

Given a \emph{not} expression $\varphi$,
we convert it to CNF by following the
steps detailed below (reproduced from Prof. Eisner):

\begin{itemize}
\item[] If $\varphi$ has the form $\neg(...)$, then:
  \begin{itemize}
  \item If $\varphi$ has the form $\neg{A}$ for some variable $A$, then return $\varphi$.
  \item If $\varphi$ has the form $\neg(\neg P)$, then return $CONVERT(P)$. (double negation)
  \item If $\varphi$ has the form $\neg(P \wedge Q)$, then return $CONVERT(\neg P \vee \neg Q)$. (de Morgan's Law)
  \item If $\varphi$ has the form $\neg(P \vee Q)$, then return $CONVERT(\neg P \wedge \neg Q)$. (de Morgan's Law)
  \end{itemize}
\end{itemize}

<<convert not to cnf>>=
match **subexpr {
    Expr::Var(n) => CNFExpr::not(n),
    Expr::Not(ref subexpr2) => subexpr2.to_cnf(),
    Expr::And(ref subexprs) => {
        let de_morganed = de_morgan(subexprs);
        Expr::Or(de_morganed).to_cnf()
    }
    Expr::Or(ref subexprs) => {
        let de_morganed = de_morgan(subexprs);
        Expr::And(de_morganed).to_cnf()
    }
}
@

<<functions>>=
fn de_morgan(exprs: &[Expr]) -> Vec<Expr> {
    exprs
        .iter()
        .map(|x| Expr::Not(Box::new(x.clone())))
        .collect::<Vec<Expr>>()
}
@

The main difference between the instructions and our code
is that the instructions expect conjunction and disjunction
to be done on only two sub-expressions at a time.  We adapt
the instructions to support our vectors of sub-expressions.

In the head of the match expression, [[subexpr]] is dereferenced
twice: once for the borrow, once for the box.

<<unit tests>>=
#[test]
fn test_convert_not_simple() {
    use super::{CNFExpr, Expr};
    assert_eq!(CNFExpr::var(0), Expr::from_str("0").to_cnf());
    assert_eq!(CNFExpr::not(0), Expr::from_str("!0").to_cnf());
    assert_eq!(CNFExpr::var(0), Expr::from_str("!!0").to_cnf());
}
@

\subsection{Converting an \emph{and} expression}

To convert an \emph{and} expression to CNF, we
convert each sub-expression to CNF and then
concatenate their clauses into one big CNFExpr.

<<convert and to cnf>>=
let mut cnf_clauses = Vec::new();
for subexpr in subexprs {
    let subexpr_cnf = subexpr.to_cnf();
    for clause in subexpr_cnf.0 {
        cnf_clauses.push(clause)
    }
}
CNFExpr(cnf_clauses)
@

\subsection{Converting an \emph{or} expression}

Converting an \emph{or} expression to CNF
is the ``big bad'': it has the potential
to make our expression grow exponentially!
We'll implement the na√Øve approach, and
we'll revisit later if this turns out to
be too much of a problem.

Per Prof. Eisner, if our initial expression
$\varphi$ has the form $P \vee Q$, then
$CONVERT(P)$ must have the form
$P_1 \wedge ... \wedge P_m$,
and $CONVERT(Q)$ must have the form
$Q_1 \wedge ... \wedge Q_n$.
In our case, the disjunction can have
more than two sub-expressions, but the
principle still holds.

Let's first convert every sub-expression to CNF.
After the conversion is done, we store the
clauses of each CNF sub-expression inside a vector.

<<convert or sub-expressions to cnf>>=
let mut cnf_clauses: Vec<Vec<CNFClause>> = Vec::new();
for subexpr in subexprs {
    let subexpr_cnf = subexpr.to_cnf();
    cnf_clauses.push(subexpr_cnf.0)
}
@

Now we have to create a [[CNFExpr]] between
each pair of clauses.  For instance, if we
have the following vector of clauses:

\begin{verbatim}
[ [C1, C2], [C3, C4, C5], [C6] ]
\end{verbatim}

We need to create the following conjunction:

\begin{verbatim}
    (C1 or C3) and (C1 or C4) and (C1 or C5) and (C1 or C6)
and (C2 or C3) and (C2 or C4) and (C2 or C5) and (C2 or C6)
and (C3 or C6) and (C4 or C6) and (C5 or C6)
\end{verbatim}

<<create large conjunction>>=
let mut new_clauses = Vec::new();
for c1 in 0 .. cnf_clauses.len() {
    for i in 0 .. cnf_clauses[c1].len() {
        for c2 in c1+1 .. cnf_clauses.len() {
            for j in 0 .. cnf_clauses[c2].len() {
                let p = cnf_clauses[c1][i].clone();
                let q = cnf_clauses[c2][j].clone();
                let mut combined: Vec<CNFLiteral> = Vec::new();
                combined.extend(p.0);
                combined.extend(q.0);
                new_clauses.push(CNFClause(combined));
            }
        }
    }
}
CNFExpr(new_clauses)
@


<<convert or to cnf>>=
<<convert or sub-expressions to cnf>>
<<create large conjunction>>
@


\section{Experiments}

In this section, we will define a number of
experiments that can be run on a stream of
expressions.  The results should be useful
to determine if the approach is viable.

Each experiment is a function that will
consume its input from [[stdin]] and output
its results on [[stdout]].

\subsection{Histogram}

Given the large number of expressions in our
input set, the results of many experiments will
best be expressed as a histogram.  In this
section, we'll implement a simple histogram
data structure.

<<type definitions>>=
struct Histogram {
    num_windows: usize,
    buckets: Vec<usize>
}

impl Histogram {
    <<histogram methods>>
}
@

The [[num_windows]] field controls how many buckets the
histogram contains, and thus the range of each bucket.
For example, if [[num_window]] is 2, there will be three
buckets: one for ratios in the range $[0, 0.5[$, one for
ratios in the range $[0.5, 1.0[$, and one for $[1.0, +\infty[$.
The tally for each range window is contained
in the vector [[buckets]].

\paragraph{Creating a histogram}
To create a histogram, the user invokes the [[new]]
method, specifying the number of windows they want.

<<histogram methods>>=
fn new(num_windows: usize) -> Histogram {
    Histogram {
        num_windows: num_windows,
        buckets: iter::repeat(0).take(num_windows + 1).collect()
    }
}
@

\paragraph{Tallying}
We tally a ratio by computing which bucket the parameter belongs to
and increasing that bucket by one.

The formula to determine the appropriate bucket for a ratio $r$ is as follows:

\[
bucket(r) = min\left( \lfloor{r \cdot \text{[[num_windows]]}}\rfloor,
\text{[[num_windows]]} \right)
\]

<<histogram methods>>=
fn tally(&mut self, r: f64) {
    let x = (r * self.num_windows as f64) as usize;
    let idx = cmp::min(x, self.num_windows);
    self.buckets[idx] += 1;
}
@

\paragraph{Unit tests}
Let's test our [[Histogram]] by create a simple one and
performing a few manual tallies.

<<unit tests>>=
#[test]
fn test_histogram() {
    use super::Histogram;
    let mut h = Histogram::new(4);
    h.tally(0.1);
    h.tally(0.3);
    h.tally(0.6);
    h.tally(0.9);
    h.tally(1.2);
    assert_eq!(1, h.buckets[0]);
    assert_eq!(1, h.buckets[1]);
    assert_eq!(1, h.buckets[2]);
    assert_eq!(1, h.buckets[3]);
    assert_eq!(1, h.buckets[4]);
}
@

\paragraph{Printing}
We'll finish our [[Histogram]] struct by writing a
method to print the results to stdout.

<<histogram methods>>=
fn display(&self) {
    let total: f64 = self.buckets.iter().sum::<usize>() as f64;
    let slice = 1.0 / (self.num_windows as f64);
    for i in 0 .. self.num_windows {
        println!("{:.2} .. {:.2} : {} ({:.2})",
            slice * (i as f64),
            slice * ((i+1) as f64),
            self.buckets[i],
            self.buckets[i] as f64 / total);
    }
    println!("1.00 .. +inf : {} ({:.2})",
        self.buckets[self.num_windows],
        self.buckets[self.num_windows] as f64 / total);
}
@



\subsection{Parsing and conversion}

For our first experiment,
let's make sure that we can properly parse expressions and
convert them to conjunctive normal form.  We read a line, parse it
into an [[Expr]], and convert to a [[CNFExpr]].  We let the program
panic if there is an error, and if we parsed everything successfully
we silently exit.

<<functions>>=
fn exp_parse_and_convert() {
    let stdin = io::stdin();
    let mut buf = String::new();

    while stdin.read_line(&mut buf).unwrap() > 0 {
        let expr = Expr::from_str(&buf);
        expr.to_cnf();
        buf.clear();
    }
}
@


\subsection{Counting common expressions}

A key assumption for our improved match strategy
is that some expressions occur in many different
expressions.  This experiment gives us the 20
most used clauses and in how many expressions
they occur.

<<functions>>=
fn count_common_expressions() {
    let exprs = read_exprs();
    let mut tallies = BTreeMap::new();
    let n = exprs.len();

    for expr in exprs.iter() {
        let cnf_expr = expr.to_cnf();
        for clause in cnf_expr.0 {
            let tally = tallies.entry(clause).or_insert(0);
            *tally += 1;
        }
    }

    let mut entries: Vec<(&CNFClause, &usize)> = tallies.iter().collect();
    entries.sort_by(|&(_, a), &(_, b)| Ord::cmp(b, a));
    for &(clause, count) in entries.iter().take(20) {
        println!("{} : {} ({:.2}%)", clause, count, (100.0 * *count as f64 / n as f64));
    }
}
@


\subsection{Size difference}

Converting from a regular expression to
a CNF expression can cause the number of
variable references to grow exponentially.

This experiments create a histogram comparing
the size of the original expression and
the size of its CNF conversion.

<<functions>>=
fn exp_size_diff() {
    let exprs = read_exprs();
    let mut h = Histogram::new(10);
    let mut total_count: usize = 0;

    for expr in exprs.iter() {
        let cnf_expr = expr.to_cnf();
        let ratio = expr.size() as f64 / cnf_expr.size() as f64;
        h.tally(ratio);
    }

    h.display();
}
@

\subsection{Detecting duplicate clauses}

One issue that caused a match strategy to panic
was the presence of duplicate clauses inside an
expression, e.g., $X \wedge (Y \vee Z) \wedge X$.
We do not want duplicates in our CNF expressions.
This experiment displays the id of a CNF expression
that has duplicate clauses and the duplicate clauses.


<<functions>>=
fn exp_duplicates() {
    let exprs = read_exprs();
    for (i, expr) in exprs.into_iter().enumerate() {
        let mut dupes = Vec::new();
        let cnf_expr = expr.to_cnf();
        for j in 0 .. cnf_expr.0.len() {
            for k in j+1 .. cnf_expr.0.len() {
                if cnf_expr.0[j] == cnf_expr.0[k] {
                    dupes.push(cnf_expr.0[j].clone());
                }
            }
        }
        if !dupes.is_empty() {
            println!("{:4}: {:?}", i, dupes);
        }
    }
}
@

\subsection{Evaluation (correctness)}

The Rust type checker accepts [[to_cnf]],
meaning that we produce an expression that
is truly in CNF form.  However, this
doesn't mean that the construction retains
the semantics of the original expression.

In this sub-section, we create an
experiment to give us greater confidence
that the conversion isn't buggy.
We convert an expression to its CNF form
and evaluate both with many randomly generated environments.

If there is a discrepancy between the results,
we know that there is a bug in our implementation.
If that happens, we output the line number of
the culprit and the environment that caused the error.

If there is no discrepancy between the results,
there may still be a bug in the code, but at least we can
feel more confident in our implementation.

\paragraph{Environment generation}
We first need to create random environments.
We shall proceed in two steps:
(1) we'll find all the variable ids used in an expression,
(2) we will insert them in an environment with a random boolean value.

<<expression methods>>=
fn vars(&self, vars: &mut HashSet<usize>) {
    match *self {
        Expr::Var(n) => { vars.insert(n); }
        Expr::Not(ref sub) => { sub.vars(vars); }
        Expr::Or(ref subs)
        | Expr::And(ref subs) => {
            for sub in subs {
                sub.vars(vars);
            }
        }
    }
}
@

<<type definitions>>=
impl Env {
    fn random(vars: &HashSet<usize>) -> Env {
        let mut rng = rand::thread_rng();
        let mut env = Env::new();
        for var in vars {
            env.insert(*var, rng.gen::<bool>());
        }
        return env;
    }
}
@

\paragraph{Simulation}
With our helper functionality in place,
all that's left to do is throw a lot of
environments at the expressions and
hope they evaluate to the same value.

<<functions>>=
fn exp_eval_correctness() {
    let exprs = read_exprs();
    let mut eval_to_true = 0;
    for (line, expr) in exprs.iter().enumerate() {
        let cnf_expr = expr.to_cnf();
        let mut vars = HashSet::new();
        expr.vars(&mut vars);
        for _ in 0 .. EVAL_ITER {
            let env = Env::random(&vars);
            let v1 = expr.eval(&env);
            let v2 = cnf_expr.eval(&env);
            if v1 { eval_to_true += 1; }
            if v1 != v2 {
                println!("Error (line {}): {:?}", line, env);
                return;
            }
        }
    }
    let n = exprs.len() * EVAL_ITER;
    println!("Evaluated to true: {}/{} ({:.2}%)",
        eval_to_true, n,
        eval_to_true as f64 / n as f64 * 100.0);
}
@


\subsection{Evaluation (speed)}

After asserting that raw expressions and their CNF versions evaluate
to the same result, we want to know about the difference in evaluation
speed.

\subsubsection{Benchmarking}

We will evaluate each expression [[EVAL_ITER]] times, and tally the
ratio between the time taken by the CNF expression over
the time taken by the vanilla expression.

<<functions>>=
fn exp_eval_speed() {
    let mut h = Histogram::new(10);
    let exprs = read_exprs();
    for expr in exprs {
        let cnf = expr.to_cnf();
        let mut vars = HashSet::new();
        expr.vars(&mut vars);
        let mut vanilla_time = 0;
        let mut cnf_time = 0;

        for _ in 0 .. EVAL_ITER {
            let env = Env::random(&vars);
            let now = Instant::now();
            expr.eval(&env);
            let elapsed = now.elapsed();
            vanilla_time += elapsed.as_secs() + (elapsed.subsec_nanos() as u64);

            let now = Instant::now();
            cnf.eval(&env);
            let elapsed = now.elapsed();
            cnf_time += elapsed.as_secs() + (elapsed.subsec_nanos() as u64);

        }

        let ratio = (cnf_time as f64) / (vanilla_time as f64);
        h.tally(ratio);
    }
    h.display();
}
@

\subsection{Evaluating all expressions (Strategy 1)}

The previous section gave us a sense of how much
time evaluating the individual expressions took.
Let's now explore the case that is closer to
\emph{rtb-boolean}'s purpose, finding the list
of expressions that match a given environment.

We'll first start with an implementation that
matches the algorithm described in [[<<find matches naively>>]]:
evaluate each expression one after the other
without attempting to leverage the commonalities
that they may share.

<<functions>>=
fn naive_match_exprs(exprs: &[Expr], env: &Env) -> usize {
    let mut matches = 0;
    for expr in exprs.iter() {
        if expr.eval(env) {
            matches += 1;
        }
    }
    return matches;
}
@

<<functions>>=
fn naive_match_cnf(cnf_exprs: &[CNFExpr], env: &Env) -> usize {
    let mut matches = 0;
    for cnf_expr in cnf_exprs.iter() {
        if cnf_expr.eval(env) {
            matches += 1;
        }
    }
    return matches;
}
@

<<functions>>=
fn exp_match_1() {
    let mut h = Histogram::new(10);
    let exprs = read_exprs();
    let cnf_exprs = exprs.iter().map(|expr| expr.to_cnf())
        .collect::<Vec<CNFExpr>>();

    let mut all_vars = HashSet::new();
    for expr in exprs.iter() {
        expr.vars(&mut all_vars);
    }

    for _ in 0 .. EVAL_ITER {
        let env = Env::random(&all_vars);

        let now = Instant::now();
        let expr_matches = naive_match_exprs(&exprs, &env);
        let elapsed = now.elapsed();
        let expr_time = 1e9 * (elapsed.as_secs() as f64) + (elapsed.subsec_nanos() as f64);

        let now = Instant::now();
        let cnf_matches = naive_match_cnf(&cnf_exprs, &env);
        let elapsed = now.elapsed();
        let cnf_time = 1e9 * (elapsed.as_secs() as f64) + (elapsed.subsec_nanos() as f64);

        assert_eq!(expr_matches, cnf_matches);
        h.tally(cnf_time as f64 / expr_time as f64);
    }
    h.display();
}
@

\subsection{Evaluating all expressions (Strategy 2)}

Having done the simple matching, let's try to use
the regularity of the conjunctive normal form to
try and evaluate fewer clauses and expressions.

\begin{itemize}
\item Keep a map from clauses to expressions that have this clause;
\item Evaluate the most common clause, i.e., the one that has the
    largest set of expressions;
\item If evaluation fails, mark all the expressions as failed;
\item Repeat until no clause remains.
\end{itemize}


<<functions>>=
fn exp_match_2() {
    let mut h1 = Histogram::new(10);
    let mut h2 = Histogram::new(10);
    let exprs = read_exprs();
    let mut expr_success = vec![true; exprs.len()];

    let mut all_vars = HashSet::new();
    for expr in exprs.iter() {
        expr.vars(&mut all_vars);
    }

    // Create a map from clause to expressions.
    let mut clause_expr: HashMap<CNFClause, HashSet<usize>> = HashMap::new();
    for (i, expr) in exprs.iter().enumerate() {
        let cnf_expr = expr.to_cnf();
        for clause in cnf_expr.0.iter() {
            let entry = clause_expr.entry(clause.clone()).or_insert(HashSet::new());
            entry.insert(i);
        }
    }

    // Order the clauses from most popular to least popular.
    let mut clause_expr_vec: Vec<(CNFClause, HashSet<usize>)> = clause_expr.into_iter().collect();
    clause_expr_vec.sort_by(|&(_, ref s1), &(_, ref s2)| Ord::cmp(&s2.len(), &s1.len()));

    for _ in 0 .. EVAL_ITER {
        let env = Env::random(&all_vars);

        let now = Instant::now();
        let expr_matches = naive_match_exprs(&exprs, &env);
        let elapsed = now.elapsed();
        let expr_time = 1e9 * (elapsed.as_secs() as f64) + (elapsed.subsec_nanos() as f64);

        let now = Instant::now();
        for &(ref clause, ref expr_ids) in clause_expr_vec.iter() {
            let x = clause.eval(&env);
            if !x {
                for i in expr_ids {
                    expr_success[*i] = false;
                }
            }
        }
        let elapsed = now.elapsed();
        let cnf_time = 1e9 * (elapsed.as_secs() as f64) + (elapsed.subsec_nanos() as f64);

        h1.tally(cnf_time / expr_time);
        h2.tally(expr_time / cnf_time);
    }
    println!("cnf over vanilla");
    h1.display();

    println!("vanilla over cnf");
    h2.display();
}
@

The results show that matching CNF expressions
in this way is slower than evaluating the regular
expressions or the CNF expressions one-by-one.

The main issue here is that we evaluate \emph{all}
the clauses.  However, we never remove clauses if
the number of still-viable expressions reaches zero.


\subsection{Removing clauses}

(My first attempt at removing clauses fell into
an insidious trap: the time to maintain the data
structures far exceeded the time required to
evaluate the clauses!)

The previous experiment showed that evaluating
every clause once was slower than going expression
by expression.  Certainly, many clauses were evaluated
that had no reason to be considered further.
In this experiment, we'll try and implement a smarter
matching mechanism that skips over clauses if they
need not be evaluated (i.e., if all the expressions
they belong to have already failed).

\paragraph{Data structures}
In order to keep track of which clauses still need
to be evaluted, we will need a number of appropriate
data structures.

\begin{description}
\item[[clauses: Vec<CNFClause>]] a vector containing all the
    clauses of all the expressions.
\item[[succeeded: Vec<bool>]] a vector containing \emph{true}
    if the $j$th expression succeeded, and \emph{false}
    otherwise.
\item[[still_needed: Vec<usize>]] a vector indexed by clause id;
    the value at index $i$ denotes the number of CNF expressions
    that may still succeed if the $i$th clause evaluates to
    \emph{true}.
    When a clause fails, we set this value to zero,
    i.e., all the expressions that depend on the $i$th clause
    \emph{will} fail, and thus the clause is no longer needed.
    If the count for a clause is zero, we need not evaluate it.
\item[[comrades: Vec<Vec<usize>>]] a vector containing
    vectors of clause ids.  The vector at position $i$
    contains the indices of all the clauses that appear
    in an expression with the $i$th clause.
\item[[exprs_of: Vec<Vec<usize>>]] a vector containing
    vectors of expression ids.  The vector at position $i$
    contains the indices of all the expressions that
    have the $i$th clause.
\end{description}

The code below illustrates how these data structures
are used to find which expressions match a given environment.

<<match with clause removal>>=
for (i, c) in clauses.iter().enumerate() {
    if still_needed[i] == 0 { continue; }
    let x = c.eval(&env);
    if !x {
        still_needed[i] = 0;
        for comrade in comrades[i].iter() { still_needed[*comrade] -= 1; }
        for expr in exprs_of[i].iter() { succeeded[*expr] = false; }
    }
}
@

\paragraph{Data structure initialization}
Let us populate the structures with the appropriate data.
As in previous experiments, the first two structures
that we initialize are the vector of expressions read
from stdin, and the set that contains the variables found
in those expressions.

<<match3 data structures initialization>>=
let exprs: Vec<Expr> = read_exprs();
let mut all_vars: HashSet<usize> = HashSet::new();
for expr in exprs.iter() {
    expr.vars(&mut all_vars);
}
@

We can initialize the [[succeeded]] vector in a single line of code:
we use Rust's [[vec!]] macro to create a vector
of length equal to the number of expressions,
and initialize all the elements to \emph{true}.

<<match3 data structures initialization>>=
let mut succeeded: Vec<bool> = vec![true; exprs.len()];
@

The other data structures, those indexed by a clause id,
require more work.  In order to help us, we'll have an
extra data structure, [[clause_ids]], a map between a
clause and its position in the [[clauses]] vector.
This structure will not be used for the actual evaluation,
but it will make the initialization easier.
The variable [[next_clause_id]] contains the index
that the next unseen clause will have.

<<match3 data structures initialization>>=
let mut clause_ids: HashMap<CNFClause, usize> = HashMap::new();
let mut clauses: Vec<CNFClause> = Vec::new();
let mut still_needed: Vec<usize> = Vec::new();
let mut comrades: Vec<HashSet<usize>> = Vec::new();
let mut exprs_of: Vec<HashSet<usize>> = Vec::new();
let mut next_clause_id = 0;
@

The code for populating the data structures is found
below.  Let us note a few salient points:
\begin{itemize}
\item When [[clause_id]] and [[next_clause_id]] are equal,
    then the clause has never been seen before and we
    have to push it into the clauses vector and add
    a new element for all other vectors index by clause id.
\item We maintain a vector, [[clause_comrades]],
    which contains the expression's clauses' ids;
    once all clauses have been processed, we use this
    vector to populate the [[comrades]] sets of the
    expressions clauses.
\end{itemize}

<<match3 data structures initialization>>=
for (expr_id, expr) in exprs.iter().enumerate() {
    let cnf_expr = expr.to_cnf();

    let mut clause_comrades = Vec::new();
    for clause in cnf_expr.0 {
        let clause_id = *clause_ids.entry(clause.clone()).or_insert(next_clause_id);
        if clause_id == next_clause_id {
            clauses.push(clause);
            still_needed.push(0);
            comrades.push(HashSet::new());
            exprs_of.push(HashSet::new());
            next_clause_id += 1;
        }
        clause_comrades.push(clause_id);
        still_needed[clause_id] += 1;
        exprs_of[clause_id].insert(expr_id);
    }
    for &com1 in clause_comrades.iter() {
        for &com2 in clause_comrades.iter() {
            if com1 != com2 {
                comrades[com1].insert(com2);
            }
        }
    }
}
@



<<functions>>=
fn exp_match_3() {
    let mut h1 = Histogram::new(10);
    let mut h2 = Histogram::new(10);

    <<match3 data structures initialization>>

    // Take a copy of structures that will mutate
    // to run the experiment multiple times.
    let orig_still_needed = still_needed.clone();
    let orig_succeeded = succeeded.clone();

    //println!("clauses     : {:?}", clauses);
    //println!("succeeded   : {:?}", succeeded);
    //println!("still_needed: {:?}", still_needed);
    //println!("comrades    : {:?}", comrades);
    //println!("exprs_of    : {:?}", exprs_of);

    for _ in 0 .. EVAL_ITER {
        let env = Env::random(&all_vars);

        let now = Instant::now();
        let expr_matches = naive_match_exprs(&exprs, &env);
        let elapsed = now.elapsed();
        let expr_time = 1e9 * (elapsed.as_secs() as f64) + (elapsed.subsec_nanos() as f64);

        succeeded = orig_succeeded.clone();
        still_needed = orig_still_needed.clone();
        let now = Instant::now();
        <<match with clause removal>>
        let elapsed = now.elapsed();
        let cnf_time = 1e9 * (elapsed.as_secs() as f64) + (elapsed.subsec_nanos() as f64);

        //assert_eq!(expr_matches, succeeded.iter().filter(|x| **x).count());
        h1.tally(cnf_time as f64 / expr_time as f64);
        h2.tally(expr_time as f64 / cnf_time as f64);
    }
    println!("cnf over vanilla");
    h1.display();

    println!("vanilla over cnf");
    h2.display();
}
@




\section{Putting it all together}

We can put invoke our different experiments
by creating a runner program that calls the
appropriate function.


<<cnf.rs>>=
extern crate rand;

use std::cmp;
use std::cmp::Ord;
use std::collections::{HashSet, BTreeMap, HashMap};
use std::env;
use std::fmt;
use std::io;
use std::iter;
use std::process;
use std::time::{Instant};

use rand::Rng;

const EVAL_ITER: usize = 10_000;

<<type definitions>>
<<parse functions>>
<<functions>>

fn interactive() {
    let exprs = read_exprs();
    for expr in exprs.iter() {
        let cnf_expr = expr.to_cnf();
        println!("{} == {}", expr, cnf_expr);
    }
}

#[cfg(not(test))]
fn main() {
    let args = env::args().collect::<Vec<String>>();
    if args.len() == 1 {
        usage();
    }
    if args[1] == "parse" {
        exp_parse_and_convert();
    } else if args[1] == "interactive" {
        interactive();
    } else if args[1] == "count" {
        count_common_expressions();
    } else if args[1] == "size_diff" {
        exp_size_diff();
    } else if args[1] == "duplicates" {
        exp_duplicates();
    } else if args[1] == "eval" {
        exp_eval_correctness();
    } else if args[1] == "bench" {
        exp_eval_speed();
    } else if args[1] == "match1" {
        exp_match_1();
    } else if args[1] == "match2" {
        exp_match_2();
    } else if args[1] == "match3" {
        exp_match_3();
    } else {
        usage();
    }
}

fn usage() -> ! {
    println!("usage: cnf <command>");
    println!("Commands:");
    println!("- parse     : try to parse the expressions.");
    println!("- count     : display the 20 most common CNF clauses and their count.");
    println!("- size_diff : display a histogram of the expression:CNF size ratios.");
    println!("- duplicates: display duplicate clauses in CNF expressions.");
    println!("- eval      : evaluate each expression and CNF expression {} times and ensure they match.", EVAL_ITER);
    println!("- bench     : display a histogram of the CNF:expression time ratios for evaluating each expression {} times.", EVAL_ITER);
    println!("- match1    : display a histogram of the CNF:expression time ratios for evaluating all expressions. Naive approach: iterate over each expression/CNF expression and invoke .eval().");
    println!("- match2    : display a histogram of the CNF:expression time ratios when evaluating one clause at a time without removals");
    process::exit(1);
}
@


<<functions>>=
fn read_exprs() -> Vec<Expr> {
    let mut exprs = Vec::new();
    let stdin = io::stdin();
    let mut buf = String::new();
    while stdin.read_line(&mut buf).unwrap() > 0 {
        let expr = Expr::from_str(&buf);
        exprs.push(expr);
        buf.clear();
    }
    return exprs;
}
@


\section{Erlang}

In this section we define an Erlang module
with a number of utility functions for
reading the flights from a [[.bert]] file,
extracting the expressions, parsing them,
replacing the literals with variables, etc.

\paragraph{Reading Flights}
Erlang's standard library provides a pair
of functions, [[file:read_file/1]] and
[[binary_to_term/1]], that are useful for
reading in a [[.bert]] file.

We perform extra processing to extract the
actual flights, and leave out the more
``meta data'' such as the name of the bert
table and the indices of the flights.

<<erlang functions>>=
read_flights(PathName) ->
    {ok, Bin} = file:read_file(PathName),
    [{flights, Entries} | _] = binary_to_term(Bin),
    [Fields || {_Id, Fields} <- Entries].
@

\paragraph{Extracting expressions}
Flights have many fields, but the only one
we are really interested in for this study
is the \emph{boolean\_expression} field.
The following function accepts the output
of [[read_flights/1]] and returns a list
of binaries.

<<erlang functions>>=
extract_expressions(Flights) ->
    [element(2, lists:keyfind(boolean_expression, 1, Flight))
    || Flight <- Flights].
@


\paragraph{Parsing expressions}
The [[parse/1]] function is pretty
straight-forward: take all the
binaries returned by [[extract_expressions/1]]
and lex and parse them.

<<erlang functions>>=
parse(Expressions) ->
    lists:map(
        fun(E) ->
            {ok, Tokens, _} = rtb_boolean_lexer:string(binary_to_list(E)),
            {ok, Ast} = rtb_boolean_parser:parse(Tokens),
            Ast
        end,
        Expressions).
@

\subsection{Deliteralizing}
To pass the flights' expressions to our
Rust program, we need to transform the
ASTs into the simpler format we defined
in \autoref{sec:expressions}.  To do this,
we explore the ASTs, we retain the
\emph{and}, \emph{or}, and \emph{not} nodes,
and convert all the other expressions
into numeric variables.

\paragraph{Deliteralizing multiple ASTs}
Our first function, [[deliteralize_asts/1]],
accepts a list of boolean expressions ASTs
and invokes the [[deliteralize/3]] function
on each one of them.

The variable [[ExprToVar]] maps boolean expressions
to pairs.  The first element of a pair is the variable node
(as defined in the boolean language) to replace the
expression with, and the second element is how many
times that expression occurs in all the ASTs.
The variable [[NextId]] is the value of the variable
that the next expression is going to take on.

<<erlang functions>>=
deliteralize_asts(Asts) ->
    lists:foldl(fun(Ast, {AccAsts, ExprToVar, Next}) ->
        {DelitAst, ExprToVar2, NextId2} = deliteralize(Ast, ExprToVar, NextId),
        {[DelitAst | AccAsts], ExprToVar2, NextId2}
    end, {[], #{}, 0}, Asts).
@


\paragraph{Deliteralizing an AST}
To deliteralize an \emph{and} or \emph{or}
node, we deliteralize their sub-expressions;
to deliteralize a \emph{not} node, we
deliteralize its sub-expression.
In both cases, the deliteralization will
return an updated expression-to-identifier
map and the value the next identifier should
have.

<<erlang functions>>=
deliteralize({ast_and, Exprs}, Map, Next) ->
    {Exprs2, Map2, Next2} = deliteralize_list(Exprs, Map, Next),
    {{ast_and, Exprs2}, Map2, Next2};

deliteralize({ast_or, Exprs}, Map, Next) ->
    {Exprs2, Map2, Next2} = deliteralize_list(Exprs, Map, Next),
    {{ast_or, Exprs2}, Map2, Next2};

deliteralize({ast_not, Expr}, Map, Next) ->
    {Expr2, Map2, Next2} = deliteralize(Expr, Map, Next),
    {{ast_not, Expr2}, Map2, Next2};
@

To deliteralize any other node,
we check if we've already seen
this expression before.  If
it's the case, we increment the
number of time it's been translated.
If we've never seen this expression
before, we create a new variable node,
set its count to 1 and increment the
[[NextId]] value.

<<erlang functions>>=
deliteralize(AstNode, Map, Next) ->
    case maps:find(AstNode, Map) of
        {ok, {VarNode, Count}} ->
            Map2 = maps:put(AstNode, {VarNode, Count+1}, Map),
            {VarNode, Map2, Next};
        error ->
            VarNode = {ast_variable, undefined, integer_to_list(Next)},
            Map2 = maps:put(AstNode, {VarNode, 1}, Map),
            {VarNode, Map2, Next + 1}
    end.
@


<<erlang functions>>=
deliteralize_list(Exprs, Map, Next) ->
    lists:foldl(fun(Expr, {AccExprs, M, N}) ->
        {Expr2, M2, N2} = deliteralize(Expr, M, N),
        {[Expr2 | AccExprs], maps:merge(M, M2), N2}
    end, {[], Map, Next}, Exprs).
@


<<cnf.erl>>=
-module(cnf).

-include_lib("rtb_boolean/include/rtb_boolean.hrl").

-compile(export_all).

<<erlang functions>>

intersperse([], _) -> [];
intersperse([X], _) -> [X];
intersperse([X, Y | Rest], Sep) -> [X, Sep | intersperse([Y | Rest], Sep)].

pp({ast_and, Exprs}) ->
    [$(, intersperse(lists:map(fun pp/1, Exprs), " & "), $)];
pp({ast_or, Exprs}) ->
    [$(, intersperse(lists:map(fun pp/1, Exprs), " | "), $)];
pp({ast_not, Expr}) ->
    [$!, $(, pp(Expr), $)];
pp({ast_variable, _, N}) ->
    N.


dump(DeliteralizedAsts, Path) ->
    {ok, Fd} = file:open(Path, [write]),
    lists:foreach(fun(Ast) ->
        file:write(Fd, pp(Ast)),
        file:write(Fd, "\n")
    end, DeliteralizedAsts),
    file:close(Fd).

@


\begin{appendices}

\section{}

In this appendix, we list all the unit tests that were used
to ensure that the program worked as expected.

<<cnf.rs>>=
#[cfg(test)]
mod test {
    use Env;
    fn make_env(bools: &[usize]) -> Env {
        let mut e = Env::new();
        for (i, b) in bools.iter().enumerate() {
            e.0.insert(i, if *b == 0 { false } else { true });
        }
        return e;
    }

    <<unit tests>>
}
@


<<unit tests>>=
<<expression evaluation tests>>
@


<<expression evaluation tests>>=
#[test]
fn test_eval() {
    use Expr::*;
    let e1 = And(vec![Var(0), Var(1), Var(2)]);
    assert_eq!(false, e1.eval(&make_env(&vec![0, 0, 0])));
    assert_eq!(false, e1.eval(&make_env(&vec![0, 0, 1])));
    assert_eq!(false, e1.eval(&make_env(&vec![0, 1, 0])));
    assert_eq!(false, e1.eval(&make_env(&vec![0, 1, 1])));
    assert_eq!(false, e1.eval(&make_env(&vec![1, 0, 0])));
    assert_eq!(false, e1.eval(&make_env(&vec![1, 0, 1])));
    assert_eq!(false, e1.eval(&make_env(&vec![1, 1, 0])));
    assert_eq!(true , e1.eval(&make_env(&vec![1, 1, 1])));

    let e2 = Or(vec![Var(0), Var(1), Var(2)]);
    assert_eq!(false, e2.eval(&make_env(&vec![0, 0, 0])));
    assert_eq!(true , e2.eval(&make_env(&vec![0, 0, 1])));
    assert_eq!(true , e2.eval(&make_env(&vec![0, 1, 0])));
    assert_eq!(true , e2.eval(&make_env(&vec![0, 1, 1])));
    assert_eq!(true , e2.eval(&make_env(&vec![1, 0, 0])));
    assert_eq!(true , e2.eval(&make_env(&vec![1, 0, 1])));
    assert_eq!(true , e2.eval(&make_env(&vec![1, 1, 0])));
    assert_eq!(true , e2.eval(&make_env(&vec![1, 1, 1])));
}
@


\end{appendices}

\end{document}
